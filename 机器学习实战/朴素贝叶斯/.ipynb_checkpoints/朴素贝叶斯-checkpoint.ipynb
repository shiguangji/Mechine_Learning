{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 背景介绍\n",
    "\n",
    "朴素贝叶斯的朴素是如下两点假设：①假设特征词之间相互独立， ②假设特征词是等价重要的\n",
    "\n",
    "优点：数据少时也能使用，可以处理多类别问题；\n",
    "缺点：对输入数据的准备方式较为敏感\n",
    "\n",
    "其理论的基础为概率的链式法则：P(X/c)P(c) = P(c/X)P(X)；\n",
    "我们要得到的是条件c下发生事件x的概率：P(X/c)，即有P(X/c) = p(c/X)P(X)/P(c)， 右边三项都可由统计得出。\n",
    "其中，X元素之间相互独立 ，即P(x1,x2,x3/c) = P(x1/c) * p(x2/c) * p(x3/c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadDataSet():\n",
    "    postingList = [['my', 'dog', 'has', 'flea', 'problems', 'help', 'please'], \n",
    "                ['maybe', 'not', 'take', 'him', 'to', 'dog', 'park', 'stupid'],\n",
    "                ['my', 'dalmation', 'is', 'so', 'cute', 'I', 'love', 'him'],\n",
    "                ['stop', 'posting', 'stupid', 'worthless', 'garbage'],\n",
    "                ['mr', 'licks', 'ate', 'my', 'steak', 'how', 'to', 'stop', 'him'],\n",
    "                ['quit', 'buying', 'worthless', 'dog', 'food', 'stupid']]\n",
    "    classVac = [0, 1, 0, 1, 0, 1]\t#1 代表侮辱性文字， 0代表正常言论\n",
    "    return postingList, classVac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建一个不重复的词表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createVocabList(dataSet):\n",
    "    vocabSet = set([])#创建一个空集\n",
    "    for document in dataSet:\n",
    "        vocabSet = vocabSet | set(document)#按位或语句，创建两个集合的并集\n",
    "    return list(vocabSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将输入变成想要的词向量形式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def setOfWords2Vec (VocabList, inputSet):\n",
    "    returnVec = [0]*len(VocabList)#创建一个所有元素为0的向量\n",
    "    for word in inputSet:\n",
    "        if word in VocabList:\n",
    "            returnVec[VocabList.index(word)] = 1\n",
    "        else:\n",
    "            print(\"the word: %s is not in my Vocabulary!\" % word)\n",
    "    return returnVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listOPosts, listClasses = loadDataSet()\n",
    "myVocabList = createVocabList(listOPosts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['not',\n",
       " 'stupid',\n",
       " 'garbage',\n",
       " 'flea',\n",
       " 'quit',\n",
       " 'my',\n",
       " 'problems',\n",
       " 'stop',\n",
       " 'worthless',\n",
       " 'him',\n",
       " 'ate',\n",
       " 'dog',\n",
       " 'food',\n",
       " 'posting',\n",
       " 'to',\n",
       " 'please',\n",
       " 'I',\n",
       " 'licks',\n",
       " 'is',\n",
       " 'cute',\n",
       " 'steak',\n",
       " 'take',\n",
       " 'has',\n",
       " 'maybe',\n",
       " 'buying',\n",
       " 'help',\n",
       " 'love',\n",
       " 'how',\n",
       " 'mr',\n",
       " 'so',\n",
       " 'park',\n",
       " 'dalmation']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myVocabList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "setOfWords2Vec(myVocabList, listOPosts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainNBO(trainMatrix, trainCategory):\n",
    "    numTrainDocs = len(trainMatrix)#在这里是6，就是6个向量\n",
    "    numWords = len(trainMatrix[0])#词袋的大小\n",
    "    pAbusive = sum(trainCategory)/float(numTrainDocs)#这是在计算p(c=1)，因为是二分类，所以另一个类的概率为1-p(c=1)，故不用求出来\n",
    "#     p0Num = zeros(numWords); p1Num = zeros(numWords)\n",
    "    p0Num = ones(numWords); p1Num = ones(numWords)#从0变1是为了防止链式法则因为个别 P(x_i/c)为0而导致整个分子为0的情况\n",
    "    p0Denom = 0.0; p1Denom = 0.0\n",
    "    for i in range(numTrainDocs):#这里是在统计(x/c)，为了得到p(x/c)\n",
    "        if trainCategory[i] == 1:\n",
    "            p1Num += trainMatrix[i]#由于词向量转为了特征向量，所以和词袋大小是等长的；\n",
    "            p1Denom += sum(trainMatrix[i])\n",
    "        else:\n",
    "            p0Num += trainMatrix[i]\n",
    "            p0Denom += sum(trainMatrix[i])\n",
    "#     p1Vect = p1Num/p1Denom#计算p(x/c)\n",
    "#     p0Vect = p0Num/p0Denom\n",
    "    p1Vect = log(p1Num/p1Denom)\n",
    "    p0Vect = log(p0Num/p0Denom)\n",
    "    return p0Vect, p1Vect, pAbusive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将输入的词向量组变成向量矩阵\n",
    "\n",
    "词向量是不等长的，向量矩阵是对应词库向量得到的等长向量组成的矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainMat = []\n",
    "for postinDoc in listOPosts:\n",
    "    trainMat.append(setOfWords2Vec(myVocabList, postinDoc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p0V, p1V, pAb = trainNBO(trainMat, listClasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "[ 0.          0.          0.          0.04166667  0.          0.125\n",
      "  0.04166667  0.04166667  0.          0.08333333  0.04166667  0.04166667\n",
      "  0.          0.          0.04166667  0.04166667  0.04166667  0.04166667\n",
      "  0.04166667  0.04166667  0.04166667  0.          0.04166667  0.          0.\n",
      "  0.04166667  0.04166667  0.04166667  0.04166667  0.04166667  0.\n",
      "  0.04166667]\n",
      "[ 0.05263158  0.15789474  0.05263158  0.          0.05263158  0.          0.\n",
      "  0.05263158  0.10526316  0.05263158  0.          0.10526316  0.05263158\n",
      "  0.05263158  0.05263158  0.          0.          0.          0.          0.\n",
      "  0.          0.05263158  0.          0.05263158  0.05263158  0.          0.\n",
      "  0.          0.          0.          0.05263158  0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(pAb)\n",
    "print(p0V)\n",
    "print(p1V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainMat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p0Vec是在c=0下的x1,x2,x3...的分布概率\n",
    "<n></n>\n",
    "pClass1是c=1的概率，即p(c=1)，而二分类的另一个概率为p(c=0) = 1-p(c=1)\n",
    "<n></n>\n",
    "实际这个分类就是看新的输入时和哪个类别的加权和较大，哪个大就是那个类别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classifyNB (vec2Classify, p0Vec, p1Vec, pClass1):\n",
    "    p1 = sum(vec2Classify * p1Vec) + log(pClass1)\n",
    "    p0 = sum(vec2Classify * p0Vec) + log(1.0 - pClass1)\n",
    "    if p1 > p0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中trainNB0函数是对训练集进行处理，得出每个类别的向量及标签；\n",
    "classifyNB是对测试集进行训练；\n",
    "<n></n>\n",
    "listOPosts, listClasses是训练集的词字符向量和标签；\n",
    "trainMat是listOPosts（词向量）的0/1表示；\n",
    "p0V和p1V是两个类别的变量分布（可以认为是每个变量的权重）\n",
    "pAb和1-pAb是两个类别的概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def testingNB():\n",
    "    listOPosts, listClasses = loadDataSet()\n",
    "    myVocabList = createVocabList(listOPosts)\n",
    "    trainMat = []\n",
    "    for postinDoc in listOPosts:\n",
    "        trainMat.append(setOfWords2Vec(myVocabList, postinDoc))\n",
    "    p0V, p1V, pAb = trainNB0(array(trainMat), array(listClasses))\n",
    "    testEntry = ['love', 'my', 'dalmation']\n",
    "    thisDoc = array(setOfWords2Vec(myVocabList, testEntry))\n",
    "    print(testEntry, 'classified as: ' , classifyNB(thisDoc, p0V, p1V, pAb))\n",
    "    testEntry = ['stupid', 'garbage']\n",
    "    thisDoc = array(setOfWords2Vec(myVocabList, testEntry))\n",
    "    print(testEntry, 'classified as: ' , classifyNB(thisDoc, p0V, p1V, pAb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
